# Copy this file to .env and fill in your actual values

# ============================================================================
# LLM Provider Configuration (NEW - Local LLM Support)
# ============================================================================

# Choose your LLM provider: "claude" or "ollama"
# Default: claude (if not set)
# LLM_PROVIDER=ollama

# Model to use (provider-specific)
# For Claude: claude-sonnet-4-5-20250929 or claude-3-5-haiku-20241022
# For Ollama: qwen2.5:7b-instruct-q4_K_M (recommended for 8GB VRAM)
# LLM_MODEL=qwen2.5:7b-instruct-q4_K_M

# Ollama base URL (only needed if not using default)
# OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# API Keys
# ============================================================================

# Anthropic API Key (REQUIRED)
# Get your key from: https://console.anthropic.com/
# Used for Claude LLM responses and Vision features (image/video analysis)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key (REQUIRED for embeddings)
# Get your key from: https://platform.openai.com/api-keys
# Used for text-embedding-3-small (1536 dimensions) for RAG and memory search
OPENAI_API_KEY=your_openai_api_key_here

# Hume AI API Keys (OPTIONAL - only for video chat with voice)
# Get your keys from: https://platform.hume.ai/settings/keys
# Used for voice emotion analysis and text-to-speech in video chat
# HUME_API_KEY=your_hume_api_key_here
# HUME_SECRET_KEY=your_hume_secret_key_here

# Whisper Provider Configuration
# Choose: "openai" or "local" (default: local)
# - openai: More accurate, especially with proper nouns, requires OPENAI_API_KEY
# - local: Free, runs with Transformers.js (~150MB model download on first use)
WHISPER_PROVIDER=local

# PostgreSQL Configuration (Local Development)
# These have defaults in the code, but can be overridden here
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=niimi_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password

# API Server Configuration
PORT=5442

# Hybrid Search Configuration
SEARCH_TOP_K=10
SEARCH_VECTOR_TOP_K=20
SEARCH_KEYWORD_TOP_K=20
SEARCH_TAXONOMY_TOP_K=20
SEARCH_USE_TAXONOMY=true
SEARCH_RRF_K=60  # RRF constant: higher = LESS weight to top-ranked results (more democratic fusion)

# RAG Relevance Threshold (0.0 - 1.0)
# Filters out low-relevance search results to prevent hallucination
# Lower = more lenient (more results, less precision)
# Higher = stricter (fewer results, more precision)
# Default: 0.4 (40% similarity)
# Typical ranges: 0.3-0.4 (lenient), 0.5-0.6 (moderate), 0.7+ (strict)
RAG_RELEVANCE_THRESHOLD=0.4

